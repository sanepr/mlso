# MLOps Heart Disease Prediction Project

[![CI/CD Pipeline](https://github.com/sanepr/mlso/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/sanepr/mlso/actions/workflows/ci-cd.yml)
[![Model Training](https://github.com/sanepr/mlso/actions/workflows/model-training.yml/badge.svg)](https://github.com/sanepr/mlso/actions/workflows/model-training.yml)
[![Tests](https://img.shields.io/badge/tests-60%20passed-brightgreen)](./tests/)
[![Coverage](https://img.shields.io/badge/coverage-70%25%2B-brightgreen)](./htmlcov/)
[![Python](https://img.shields.io/badge/python-3.10.11-blue)](https://www.python.org/)
[![Code Style](https://img.shields.io/badge/code%20style-black-black)](https://github.com/psf/black)
[![Project Status](https://img.shields.io/badge/status-production%20ready-brightgreen)](./docs/CI_CD_PIPELINE_SUMMARY.md)
[![Docker](https://img.shields.io/badge/docker-configured-blue)](./Dockerfile)
[![Kubernetes](https://img.shields.io/badge/kubernetes-ready-brightgreen)](./deployment/kubernetes/)

> **üìä Project Verified:** Complete CI/CD pipeline with 60 automated tests. See [CI/CD Summary](./docs/CI_CD_PIPELINE_SUMMARY.md) for details.

## üìã Project Overview

An end-to-end MLOps solution for predicting heart disease risk using the UCI Heart Disease dataset. This project demonstrates modern ML engineering practices including automated CI/CD, experiment tracking, containerization, and production deployment.

## üéØ Objectives

- Build scalable ML classification models
- Implement automated CI/CD pipelines
- Track experiments with MLflow
- Deploy containerized API to cloud
- Monitor production model performance

## üìä Dataset

**Heart Disease UCI Dataset**
- Source: UCI Machine Learning Repository
- Features: 14+ clinical features (age, sex, blood pressure, cholesterol, etc.)
- Target: Binary classification (presence/absence of heart disease)

## üèóÔ∏è Project Structure

```
mlso/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Raw dataset files
‚îÇ   ‚îú‚îÄ‚îÄ processed/              # Cleaned and processed data
‚îÇ   ‚îî‚îÄ‚îÄ download_data.py        # Data acquisition script
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda.ipynb           # Exploratory Data Analysis
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_model_training.ipynb
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py   # Data cleaning and preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_engineering.py
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py          # Model training scripts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict.py        # Prediction logic
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ app.py            # FastAPI application
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ test_features.py
‚îÇ   ‚îî‚îÄ‚îÄ test_model.py
‚îú‚îÄ‚îÄ deployment/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îú‚îÄ‚îÄ kubernetes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ingress.yaml
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/
‚îÇ       ‚îú‚îÄ‚îÄ prometheus.yml
‚îÇ       ‚îî‚îÄ‚îÄ grafana-dashboard.json
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ ml-pipeline.yml    # CI/CD pipeline
‚îú‚îÄ‚îÄ models/                     # Saved model artifacts
‚îú‚îÄ‚îÄ screenshots/                # Documentation screenshots
‚îú‚îÄ‚îÄ mlruns/                     # MLflow tracking
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ setup.py
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Getting Started

### Prerequisites

- Python 3.9+
- Docker
- Kubernetes (Minikube/Docker Desktop) or cloud account
- Git

### Installation

1. Clone the repository:
```bash
git clone https://github.com/sanepr/mlso.git
cd mlso
```

2. Create virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Download dataset:
```bash
python data/download_data.py
```

## üìà Experiment Tracking

Start MLflow UI:
```bash
mlflow ui
```

Access at: http://localhost:5000

## üß™ Running Tests

### Quick Test Run
```bash
# Run all tests with comprehensive report
./run_tests.sh
```

### Manual Testing
```bash
# Run all tests
pytest tests/ -v --cov=src

# Run specific test suite
pytest tests/test_data_preprocessing.py -v
pytest tests/test_model_training.py -v
pytest tests/test_api_infrastructure.py -v

# Run with coverage report
pytest tests/ -v --cov=src --cov-report=html --cov-report=term

# Run with specific markers
pytest tests/ -m unit
pytest tests/ -m "not slow"
```

### Test Coverage
- **Total Tests:** 60 comprehensive test cases
- **Coverage Target:** ‚â•70%
- **Test Suites:**
  - Data Processing (18 tests)
  - Model Training (20 tests)
  - API Infrastructure (22 tests)

**Reports Generated:**
- HTML coverage report: `htmlcov/index.html`
- Test report: `test-report.html`
- Coverage XML: `coverage.xml`

## üîÑ CI/CD Pipeline

### Automated Workflows

**CI/CD Pipeline** (`.github/workflows/ci-cd.yml`):
- **Lint:** Code quality checks (flake8, pylint, black, isort)
- **Test:** Unit tests with coverage (‚â•70%)
- **Train:** Model training and validation
- **Build:** Docker image creation
- **Report:** Pipeline summary generation

**Model Training Pipeline** (`.github/workflows/model-training.yml`):
- **Schedule:** Weekly retraining (Sundays at midnight)
- **Validation:** Performance threshold checks (Accuracy ‚â•70%, ROC-AUC ‚â•75%)
- **Artifacts:** Trained models, MLflow logs, training reports

### Running CI/CD Locally

```bash
# Run linting
flake8 src tests
pylint src
black --check src tests
isort --check-only src tests

# Run tests with coverage
pytest tests/ -v --cov=src --cov-report=html

# Run comprehensive test suite
./run_tests.sh
```

### Pipeline Features
- ‚úÖ Automated testing on every push/PR
- ‚úÖ Code quality enforcement
- ‚úÖ Model performance validation
- ‚úÖ Docker image building and testing
- ‚úÖ Artifact storage (90 days for models)
- ‚úÖ PR comments with test results

**üìö Complete CI/CD Documentation:** [CI_CD_DOCUMENTATION.md](./CI_CD_DOCUMENTATION.md)

## üê≥ Docker Build & Run

> **‚ö†Ô∏è IMPORTANT:** Docker Desktop must be installed and **running** before using Docker commands!

### Prerequisites
- ‚úÖ Docker Desktop installed and **RUNNING** (whale icon in menu bar should be static)
- ‚úÖ Models trained (run `python src/models/train.py` first)

### Quick Start (Recommended)
```bash
# Use the automated helper script (checks Docker, builds, and optionally runs)
./docker_start.sh

# Or use the test script
./test_docker.sh
```

### Manual Build & Run

Build the container:
```bash
docker build -t heart-disease-api:latest .
```

Run locally:
```bash
# Clean up any existing containers
docker stop heart-disease-api 2>/dev/null || true
docker rm heart-disease-api 2>/dev/null || true

# Run the container
docker run -d -p 8000:8000 --name heart-disease-api heart-disease-api:latest

# Check logs
docker logs -f heart-disease-api
```

Test the API:
```bash
# Health check
curl http://localhost:8000/health

# Prediction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d @test_sample.json

# Or inline
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"age": 63, "sex": 1, "cp": 3, "trestbps": 145, "chol": 233, "fbs": 1, "restecg": 0, "thalach": 150, "exang": 0, "oldpeak": 2.3, "slope": 0, "ca": 0, "thal": 1}'
```

### Troubleshooting

#### ‚ùå Error: "Cannot connect to the Docker daemon"
**This means Docker Desktop is not running!**

**Solution:**
1. **Open Docker Desktop application** (search in Spotlight/Applications)
2. Wait for Docker to fully start (whale icon in menu bar should stop animating)
3. Verify Docker is running:
   ```bash
   docker info
   ```
4. If successful, you'll see Docker information. Now retry your command.

**Quick Check:**
```bash
# This should return version info, not an error
docker --version
docker info
```

**üìö See detailed guides:**
- [DOCKER_QUICK_FIX.md](./DOCKER_QUICK_FIX.md) - 3-step visual guide
- [DOCKER_DAEMON_FIX.md](./DOCKER_DAEMON_FIX.md) - Complete troubleshooting

#### Other Issues
See [DOCKER_FIX.md](DOCKER_FIX.md) for detailed troubleshooting guide.

## ‚ò∏Ô∏è Kubernetes Deployment

> **‚ö†Ô∏è CRITICAL:** Docker Desktop MUST be running before Kubernetes deployment!  
> Kubernetes uses Docker to run containers. Without Docker, deployment will fail.

### Prerequisites
- ‚úÖ **Docker Desktop installed and RUNNING** (whale icon in menu bar must be static)
- ‚úÖ Minikube binary available (`minikube-darwin-arm64` included in project)
- ‚úÖ Docker image built (`docker build -t heart-disease-api:latest .`)

### Quick Start (Recommended)
```bash
# Automated deployment
./deploy_k8s.sh
```

This will:
- Start minikube if needed
- Load Docker image
- Deploy to Kubernetes
- Test endpoints

### Manual Deployment

**Step 1: Start Minikube**
```bash
./minikube-darwin-arm64 start --driver=docker
```

**Step 2: Load Image**
```bash
./minikube-darwin-arm64 image load heart-disease-api:latest
```

**Step 3: Deploy**
```bash
# Using minikube's kubectl
./minikube-darwin-arm64 kubectl -- apply -f deployment/kubernetes/

# Or use the wrapper
./kubectl.sh apply -f deployment/kubernetes/
```

**Step 4: Check Status**
```bash
./kubectl.sh get pods
./kubectl.sh get services
```

**Step 5: Access Service**
```bash
# Get service URL
./minikube-darwin-arm64 service heart-disease-api --url

# Or use port forwarding
./kubectl.sh port-forward svc/heart-disease-api 8080:8000
```

### Access Your Deployment

After successful deployment, access your API:

#### Option 1: Direct NodePort (Easiest)
```bash
# Get the URL
./get_k8s_url.sh

# Or manually construct: http://<MINIKUBE_IP>:30080
curl http://192.168.49.2:30080/health
```

#### Option 2: Port Forward
```bash
./minikube-darwin-arm64 kubectl -- port-forward svc/heart-disease-api 8080:8000
# Access at http://localhost:8080
```

#### Option 3: Minikube Service
```bash
./minikube-darwin-arm64 service heart-disease-api
# Opens browser with service URL
```

**üìö Complete access guide:** [MINIKUBE_ACCESS_GUIDE.md](./MINIKUBE_ACCESS_GUIDE.md)

### Troubleshooting

#### ‚ùå Error: "Docker daemon is not running"
**Kubernetes requires Docker Desktop to be running!**

**Quick Fix:**
1. Open Docker Desktop application
2. Wait for whale icon to stop animating (30-60 seconds)
3. Verify: `docker info`
4. Retry: `./deploy_k8s.sh`

**üìö Detailed guides:**
- [K8S_DOCKER_NOT_RUNNING.md](./K8S_DOCKER_NOT_RUNNING.md) - Complete Docker fix guide
- [K8S_SETUP_SUMMARY.md](./K8S_SETUP_SUMMARY.md) - Full Kubernetes troubleshooting

#### Other Issues
See [K8S_SETUP_SUMMARY.md](K8S_SETUP_SUMMARY.md) for complete guide and troubleshooting.

## üìä Monitoring

Access Prometheus: http://localhost:9090
Access Grafana: http://localhost:3000

## üìù Model Training

```bash
python src/models/train.py
```

## üîÑ CI/CD Pipeline

The GitHub Actions pipeline automatically:
- Runs linting and code quality checks
- Executes unit tests
- Trains and validates models
- Builds Docker images
- Deploys to staging/production

## üìÑ Documentation

Comprehensive documentation is available in the [`docs/`](./docs/) folder:

### üöÄ Quick Start Guides
- **[docs/QUICK_START_GITHUB.md](./docs/QUICK_START_GITHUB.md)** - Get started with GitHub Actions
- **[docs/QUICK_START.md](./docs/QUICK_START.md)** - Project quick start

### üîÑ CI/CD Pipeline
- **[docs/CI_CD_DOCUMENTATION.md](./docs/CI_CD_DOCUMENTATION.md)** - Complete CI/CD guide (600+ lines)
- **[docs/GITHUB_PIPELINE_SETUP_GUIDE.md](./docs/GITHUB_PIPELINE_SETUP_GUIDE.md)** - Setup with 50 screenshots
- **[docs/CI_CD_QUICK_REFERENCE.md](./docs/CI_CD_QUICK_REFERENCE.md)** - Quick commands

### üê≥ Docker & Kubernetes
- **[docs/DOCKER_API_WORKING.md](./docs/DOCKER_API_WORKING.md)** - Docker setup
- **[docs/KUBERNETES_COMPLETE.md](./docs/KUBERNETES_COMPLETE.md)** - K8s deployment
- **[docs/MINIKUBE_ACCESS_GUIDE.md](./docs/MINIKUBE_ACCESS_GUIDE.md)** - Minikube guide

### üß™ Testing & Troubleshooting
- **[docs/TEST_FAILURES_FIXED.md](./docs/TEST_FAILURES_FIXED.md)** - Test solutions
- **[docs/MODEL_VALIDATION_FIXED.md](./docs/MODEL_VALIDATION_FIXED.md)** - Validation fixes

**üìö See [docs/README.md](./docs/README.md) for complete documentation index with 40+ guides**

## ü§ñ AI Tool Instructions

This project includes instructions for AI assistants (GitHub Copilot, ChatGPT, Claude, etc.) to maintain consistent documentation:

- **[AI_DOCUMENTATION_NAMING_INSTRUCTIONS.md](./AI_DOCUMENTATION_NAMING_INSTRUCTIONS.md)** - Complete guide for all AI tools
- **[.copilot-instructions.md](./.copilot-instructions.md)** - GitHub Copilot specific instructions

### Documentation Naming Convention
All documentation files (except README.md) follow this format:
```
docs/YYYYMMDD_HHMMSS_DESCRIPTIVE_NAME.md
```

**Example:** `docs/20251228_143022_DOCKER_FIX_SUMMARY.md`

When using AI tools to create documentation, they will automatically follow this naming convention.

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## üìß Contact

Your Name - sanepr

Project Link: [https://github.com/sanepr/mlso](https://github.com/sanepr/mlso)

## üìú License

This project is for educational purposes as part of MLOps coursework.
